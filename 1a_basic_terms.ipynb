{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "GROQ_API_KEY =os.environ.get(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Artificial Intelligence (AI) refers to the development of computer systems that can perform tasks that typically require human intelligence, such as:\\n\\n1. **Learning**: AI systems can learn from data and improve their performance over time.\\n2. **Problem-solving**: AI systems can analyze problems and find solutions.\\n3. **Reasoning**: AI systems can draw inferences and make decisions based on available data.\\n4. **Perception**: AI systems can interpret and understand data from sensors, such as images, speech, and text.\\n\\nThe goal of AI is to create systems that can think and act like humans, or even surpass human capabilities in specific domains. AI has many applications, including:\\n\\n1. **Virtual assistants**: AI-powered virtual assistants, such as Siri, Alexa, and Google Assistant, can understand voice commands and perform tasks.\\n2. **Image recognition**: AI-powered image recognition systems can identify objects, people, and patterns in images.\\n3. **Natural Language Processing (NLP)**: AI-powered NLP systems can understand and generate human language.\\n4. **Predictive analytics**: AI-powered predictive analytics systems can analyze data and make predictions about future events.\\n5. **Robotics**: AI-powered robots can perform tasks that require human-like intelligence, such as assembly, navigation, and manipulation.\\n\\nThere are several types of AI, including:\\n\\n1. **Narrow or Weak AI**: Designed to perform a specific task, such as image recognition or language translation.\\n2. **General or Strong AI**: Designed to perform any intellectual task that a human can.\\n3. **Superintelligence**: Significantly more intelligent than the best human minds, potentially leading to significant advancements or risks.\\n4. **Cognitive architectures**: Designed to simulate human cognition and provide a framework for integrating multiple AI systems.\\n\\nAI has many benefits, including:\\n\\n1. **Increased efficiency**: AI can automate repetitive tasks and free up human time for more creative and strategic work.\\n2. **Improved accuracy**: AI can perform tasks with high accuracy and precision, reducing errors and improving outcomes.\\n3. **Enhanced decision-making**: AI can analyze large datasets and provide insights that inform human decision-making.\\n\\nHowever, AI also raises concerns, such as:\\n\\n1. **Job displacement**: AI may automate jobs, potentially displacing human workers.\\n2. **Bias and fairness**: AI systems can perpetuate biases and discrimination if they are trained on biased data.\\n3. **Security and privacy**: AI systems can pose security and privacy risks if they are not designed and implemented with adequate safeguards.\\n\\nOverall, AI has the potential to transform many aspects of our lives, from healthcare and education to transportation and entertainment. As AI continues to evolve, it's essential to address the challenges and concerns associated with its development and deployment.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 553, 'prompt_tokens': 38, 'total_tokens': 591, 'completion_time': 2.010909091, 'prompt_time': 0.004812704, 'queue_time': 0.061902654, 'total_time': 2.015721795}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_5f849c5a0b', 'finish_reason': 'stop', 'logprobs': None}, id='run-7fe5aaed-9f6c-4928-bee3-c21f8fe78936-0', usage_metadata={'input_tokens': 38, 'output_tokens': 553, 'total_tokens': 591})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm =ChatGroq(model=\"llama-3.3-70b-versatile\")\n",
    "llm.invoke(\"what is ai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pydanic class\n",
    "If we want the model to return a Pydantic object, we just need to pass in the desired Pydantic class. The key advantage of using Pydantic is that the model-generated output will be validated. Pydantic will raise an error if any required fields are missing or if any fields are of the wrong type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Joke(A='Why did the dog go to the vet?', B='Because he was feeling ruff!', rating=8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel,Field\n",
    "from typing import Optional\n",
    "\n",
    "class Base(BaseModel): #It automatically validates types and raises errors for invalid data.\n",
    "    name:str\n",
    "    model_provider:str\n",
    "    prompt :str\n",
    "    chat:Optional[str]\n",
    "\n",
    "# Pydantic\n",
    "class Joke(BaseModel):\n",
    "    \"\"\"Joke to tell user.\"\"\"\n",
    "\n",
    "    A: str = Field(description=\"The A of the joke\")\n",
    "    B: str = Field(description=\"The B to the joke\")\n",
    "    rating: Optional[int] = Field(\n",
    "        default=None, description=\"How funny the joke is, from 1 to 10\"\n",
    "    )\n",
    "\n",
    "\n",
    "structured_llm = llm.with_structured_output(Joke)\n",
    "\n",
    "structured_llm.invoke(\"Tell me a joke about dog\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TypedDict or JSON Schema\n",
    "If you don't want to use Pydantic, explicitly don't want validation of the arguments, or want to be able to stream the model outputs, you can define your schema using a TypedDict class. We can optionally use a special Annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'setup': 'Why did the cat join a band?',\n",
       " 'punchline': 'Because it wanted to be the purr-cussionist',\n",
       " 'rating': 8}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Optional\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "\n",
    "\n",
    "# TypedDict\n",
    "class Joke(TypedDict):\n",
    "    \"\"\"Joke to tell user.\"\"\"\n",
    "\n",
    "    setup: Annotated[str, ..., \"The setup of the joke\"]\n",
    "\n",
    "    # Alternatively, we could have specified setup as:\n",
    "\n",
    "    # setup: str                    # no default, no description\n",
    "    # setup: Annotated[str, ...]    # no default, no description\n",
    "    # setup: Annotated[str, \"foo\"]  # default, no description\n",
    "\n",
    "    punchline: Annotated[str, ..., \"The punchline of the joke\"]\n",
    "    rating: Annotated[Optional[int], None, \"How funny the joke is, from 1 to 10\"]\n",
    "\n",
    "\n",
    "structured_llm = llm.with_structured_output(Joke)\n",
    "\n",
    "structured_llm.invoke(\"Tell me a joke about cats\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[add(a=3, b=4)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel,Field\n",
    "from langchain_core.output_parsers import PydanticToolsParser\n",
    "\n",
    "class add(BaseModel):\n",
    "    \"\"\"Add the numbers\"\"\"\n",
    "    a:int \n",
    "    b:int\n",
    "\n",
    "class multi(BaseModel):\n",
    "    \"\"\"Multi the numbers\"\"\"\n",
    "    a:int\n",
    "    b:int\n",
    "\n",
    "tool=[add,multi]\n",
    "\n",
    "llm_tool=llm.bind_tools(tool)\n",
    "chain=llm_tool|PydanticToolsParser(tools=[add,multi])\n",
    "\n",
    "chain.invoke(\"What is  add 3 + 4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# chache \n",
    "use to reduce the llm calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It fetch the repeated question from llm chache\n",
    "from langchain_core.globals import set_llm_cache\n",
    "from langchain_core.caches import InMemoryCache\n",
    "set_llm_cache(InMemoryCache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can do the same thing with a SQLite cache\n",
    "from langchain_community.cache import SQLiteCache\n",
    "\n",
    "set_llm_cache(SQLiteCache(database_path=\".langchain.db\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
